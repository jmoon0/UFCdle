import requests as req
from lxml import html
import datetime as dt
import random
import time


def safe_xpath(xml, xpath, default="Unknown"):
    result = xml.xpath(xpath)
    return result[0] if result else default

def parse_sherdog_fighter(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36"}
    htm = req.get(url, headers = headers)
    xml = html.document_fromstring(htm.content)
    
    
    wins_detailed = xml.xpath("//div[@class='wins']/div[@class='meter']/div[1]/text()")
    losses_detailed = xml.xpath("//div[@class='loses']/div[@class='meter']/div[1]/text()")
    bio = xml.xpath("//div[@class='fighter-info']")[0]
    
    try:
        other_wins = wins_detailed[3]
        other_losses = losses_detailed[3]
    except IndexError:
        other_wins = '0'
        other_losses = '0'

    fighter = {
        'name' : xml.xpath("//span[@class='fn']/text()")[0],
        'nationality' : bio.xpath("//strong[@itemprop='nationality']/text()")[0],
        'birthplace' : xml.xpath("//span[@class='locality']/text()")[0],
        'birthdate' : xml.xpath("//span[@itemprop='birthDate']/text()")[0],
        'age' : xml.xpath("//span[@itemprop='birthDate']/preceding-sibling::b/text()")[0],
        'height' : xml.xpath("//b[@itemprop='height']/text()")[0],
        'weight' : xml.xpath("//b[@itemprop='weight']/text()")[0],
        'weight_class' : xml.xpath("//div[@class='association-class']/a/text()")[0],

        'wins' : {
            'total': xml.xpath("//div[@class='winloses win']/span[2]/text()")[0],
            'ko/tko': wins_detailed[0],
            'submissions':wins_detailed[1],
            'decisions':wins_detailed[2],
            'others': other_wins
                },
        'losses' : {
            'total': xml.xpath("//div[@class='winloses lose']/span[2]/text()")[0],
            'ko/tko': losses_detailed[0],
            'submissions':losses_detailed[1],
            'decisions':losses_detailed[2],
            'others':other_losses
                },

        'fights' : []
    }

    #Not needed for current game
    #Adds fighter'sprevious fight data
    """fight_rows = xml.xpath("//table[@class='new_table fighter']/tr[not(@class='table_head')]")

    for row in fight_rows:
        try:
            referee =  row.xpath("td[4]/span/a/text()")[0]
        except IndexError:
            referee = ""

        fight = {
            'name': safe_xpath(row, "td[3]/a/descendant-or-self::*/text()"),
            'date': safe_xpath(row, "td[3]/span/text()"),
            'url': "https://www.sherdog.com" + safe_xpath(row, "td[3]/a/@href", ""),
            'result': safe_xpath(row, "td[1]/span/text()"),
            'method': safe_xpath(row, "td[4]/b/text()"),
            'referee': safe_xpath(row, "td[4]/span/a/text()"),
            'round': safe_xpath(row, "td[5]/text()"),
            'time': safe_xpath(row, "td[6]/text()"),
            'opponent': safe_xpath(row, "td[2]/a/text()")
        }
        fighter['fights'].append(fight)"""
    return fighter

def get_ufc_stats(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36"}
    htm = req.get(url, headers = headers)
    xml = html.document_fromstring(htm.content)

    #str_tds = xml.xpath("//dd/text()")
    str_tds = []
    for item in xml.xpath("//dd"):
        if item.text is not None:
            str_tds.append(item.text)
        else:
            str_tds.append("0")

    distance = xml.xpath("//div[@class='c-stat-3bar__value']/text()")
    stats = xml.xpath("//div[@class='c-stat-compare__number']/text()")

    fighter = {
        'strikes': {
            'attempted': str_tds[1] if len(str_tds) > 1 else "0",
            'landed': str_tds[0] if len(str_tds) > 0 else "0",
            'standing': distance[0].split(" ")[0] if len(distance) > 0 else "0",
            'clinch': distance[1].split(" ")[0] if len(distance) > 1 else "0",
            'ground': distance[2].split(" ")[0] if len(distance) > 2 else "0",
            'striking defense': stats[4].strip() if len(stats) > 4 else "0",
            'strikes per minute': stats[0].strip() if len(stats) > 0 else "0"
        },
        'takedowns': {
            'attempted': str_tds[3] if len(str_tds) > 3 else "0",
            'landed': str_tds[2] if len(str_tds) > 2 else "0",
            'takedown defense': stats[5].strip() if len(stats) > 5 else "0",
            'subs per 15min': stats[3].strip() if len(stats) > 3 else "0"
        }
    }
    return fighter

user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_4_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4.1 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0",
]

#Added random user agent selection and delay between requests
def search(query):
    url = 'https://www.google.com/search?q=' + query
    headers = {"User-Agent": random.choice(user_agents)}

    time.sleep(random.uniform(1,4))
    
    htm = req.get(url, headers = headers)
    xml = html.document_fromstring(htm.content)
    return xml.xpath("//h3/parent::a/@href")

def get_sherdog_link(query):
    possible_urls = search(query+" Sherdog")
    for url in possible_urls:
        if ("sherdog.com/fighter/" in url) and (not "/news/" or "/videos" in url):
            return url
    
    # If no exact match found, try a more lenient search
    for url in possible_urls:
        if "sherdog.com" in url and "fighter" in url:
            return url
    
    print(f"Sherdog link not found for {query}")
    return None

from urllib.parse import unquote, urlparse, parse_qs, urlencode, urlunparse
#Some links kept returning with &rut parameter for some reason
def clean_url(url):
    url = unquote(url)
    
    # Manually separate query parameters if they are in the path
    if '&rut=' in url:
        path, query = url.split('&rut=', 1)
        path += '?'
        url = path + query

    parsed_url = urlparse(url)
    
    # Rebuild the URL without any query parameters
    cleaned_url = urlunparse(
        (parsed_url.scheme, parsed_url.netloc, parsed_url.path, parsed_url.params, '', parsed_url.fragment)
    )
    
    return cleaned_url

#**Use duckduckgo for getting ufc links since google is not displaying them anymore for some reason
def search_duckduckgo(query):
    url = f'https://duckduckgo.com/html/?q={query}'
    headers = {"User-Agent": random.choice(user_agents)}

    time.sleep(random.uniform(1,4))
    
    response = req.get(url, headers=headers)
    tree = html.fromstring(response.content)

    urls_with_redirect = tree.xpath("//a[@class='result__a']/@href")
    urls = [clean_url(url.split("uddg=")[-1]) for url in urls_with_redirect]

    urls = [url for url in urls if url]

    return urls

def get_ufc_link(query):
    #**Use duckduckgo for getting ufc links since google is not displaying them anymore for some reason
    possible_urls = search_duckduckgo(query + " UFC.com")
    for url in possible_urls:
        if ("ufc.com/athlete/" in url):
            return url
    
    # If no exact match found, try a more lenient search
    for url in possible_urls:
        if "ufc.com" in url and "athlete" in url:
            return url
    
    print(f"UFC link not found for {query}")
    return None

def get_fighter(query):
    sherdog_link = get_sherdog_link(query)
    ufc_link = get_ufc_link(query)
    
    fighter = parse_sherdog_fighter(sherdog_link)
    fighter.update(get_ufc_stats(ufc_link))
    return fighter

#Getting events feature not needed for game
'''
def get_upcoming_event_links():
    url = 'https://www.ufc.com/events'
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36"}
    htm = req.get(url, headers = headers)
    xml = html.document_fromstring(htm.content)
    return ["https://www.ufc.com/"+x for x in xml.xpath("//details[@id='events-list-upcoming']/div/div/div/div/div/section/ul/li/article/div[1]/div/a/@href")]

def get_ufc_link_event(query):
    possible_urls = search(query+" UFC")
    for url in possible_urls:
        if ("ufc.com/event/" in url):
            return url
    raise BaseException("UFC link not found !")
    
def get_ranking(fight, corner):
    if corner == 'red':
        path = "div/div/div/div[2]/div[2]/div[2]/div[1]/span/text()"
    else:
        path = "div/div/div/div[2]/div[2]/div[2]/div[2]/span/text()"
        
    try:
        return fight.xpath(path)[0][1:]
    except IndexError:
        return "Unranked"
    
def get_name(fight, corner):
    if corner == 'red':
        path = "div/div/div/div[2]/div[2]/div[5]/div[1]/a/span/text()"
    else:
        path = "div/div/div/div[2]/div[2]/div[5]/div[3]/a/span/text()"
        
    name = " ".join(fight.xpath(path))
    
    if name == '':
        path = path.replace("/span", "")
        name = " ".join(fight.xpath(path)).strip()
    
    return name

def parse_event(url, past=True):
    
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36"}
    htm = req.get(url, headers = headers)
    xml = html.document_fromstring(htm.content)
    fights_html = xml.xpath("//div[@class='fight-card']/div/div/section/ul/li")
    
    prefix = xml.xpath("//div[@class='c-hero__header']/div[1]/div/h1/text()")[0].strip()
    names = xml.xpath("//div[@class='c-hero__header']/div[2]/span/span/text()")

    name = f"{prefix}: {names[0].strip()} vs. {names[-1].strip()}"

    date = dt.datetime.fromtimestamp(int(xml.xpath("//div[@class='c-hero__bottom-text']/div[1]/@data-timestamp")[0]))
    date = date.strftime("%Y-%m-%d")
    location = xml.xpath("//div[@class='c-hero__bottom-text']/div[2]/div/text()")[0].split(",")

    event = {
        'name': name,
        'date': date,
        'location': location[1].strip(),
        'venue': location[0].strip(),
        'fights': []
    }
    for fight in fights_html:
        this_fight = {
                'weightclass': fight.xpath("div/div/div/div[2]/div[2]/div[1]/div[2]/text()")[0][:-5],
                'red corner': {
                    'name': get_name(fight, 'red'),
                    'ranking': get_ranking(fight, 'red'),
                    'odds': fight.xpath("div/div/div/div[4]/div[2]/span[1]/span/text()")[0],
                    'link': fight.xpath("div/div/div/div[2]/div[2]/div[5]/div[1]/a/@href")[0]
                },
                'blue corner': {
                    'name': get_name(fight, 'blue'),
                    'ranking': get_ranking(fight, 'blue'),
                    'odds': fight.xpath("div/div/div/div[4]/div[2]/span[3]/span/text()")[0],
                    'link': fight.xpath("div/div/div/div[2]/div[2]/div[5]/div[3]/a/@href")[0]            
                }
            }
        if past:
            result = fight.xpath("div/div/div/div[2]//div[@class='c-listing-fight__outcome-wrapper']/div/text()")
            method = fight.xpath("div//div[@class='c-listing-fight__result-text method']/text()")
            
            finished_round = fight.xpath("div//div[@class='c-listing-fight__result-text round']/text()")
            finished_time = fight.xpath("div//div[@class='c-listing-fight__result-text time']/text()")
            
            this_fight['round'] = finished_round[0]
            this_fight['time'] = finished_time[0]
            this_fight['method'] = method[0]
            this_fight['red corner']['result'] = result[0].strip()
            this_fight['blue corner']['result'] = result[1].strip()
        event['fights'].append(this_fight)
    return event

def get_upcoming_events():
    links = get_upcoming_event_links()
    
    results = {}
    
    for url in links:
        event = parse_event(url, False)
        results[event['name']] = event
    return results

def get_event(query):
    link = get_ufc_link_event(query)
    return parse_event(link)
'''